{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoders.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijGQa7T9dWmM",
        "colab_type": "text"
      },
      "source": [
        "# What are autoencoders?\n",
        "\n",
        "\n",
        "![alt text](https://blog.keras.io/img/ae/autoencoder_schema.jpg)\n",
        "\n",
        "\"Autoencoding\" is a data compression algorithm where the compression and decompression functions are 1) data-specific, 2) lossy, and 3) learned automatically from examples rather than engineered by a human. Additionally, in almost all contexts where the term \"autoencoder\" is used, the compression and decompression functions are implemented with neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK2idAV4eewZ",
        "colab_type": "text"
      },
      "source": [
        "# What are autoencoders good for?\n",
        "\n",
        "Today two interesting practical applications of autoencoders are **data denoising** (which we feature later in this post), and **dimensionality reduction for data visualization**. With appropriate dimensionality and sparsity constraints, autoencoders can learn data projections that are more interesting than PCA or other basic techniques.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtWCGLXNfdRu",
        "colab_type": "text"
      },
      "source": [
        "# Let's build the simplest possible autoencoder\n",
        "\n",
        "We'll start simple, with a single fully-connected neural layer as encoder and as decoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9AZ98DvdI2V",
        "colab_type": "code",
        "outputId": "bde74113-048c-4d1c-8818-f934d4041db6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "# this is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# this is our input placeholder\n",
        "input_img = Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0618 01:57:29.093987 139742053783424 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0618 01:57:29.122325 139742053783424 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0618 01:57:29.128806 139742053783424 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm_3nnprj6Vg",
        "colab_type": "code",
        "outputId": "19465427-22e7-42af-cc9f-2e9691f14178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 784)               25872     \n",
            "=================================================================\n",
            "Total params: 50,992\n",
            "Trainable params: 50,992\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDjjZKoHLMLj",
        "colab_type": "text"
      },
      "source": [
        "Let's also create a separate encoder model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "povP6atBLN4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this model maps an input to its encoded representation\n",
        "#this is optional for now\n",
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H28MnHqFkqrc",
        "colab_type": "code",
        "outputId": "bb56d085-5f45-4be8-f80c-21dd5c675eb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                25120     \n",
            "=================================================================\n",
            "Total params: 25,120\n",
            "Trainable params: 25,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkq7hzFDLTIv",
        "colab_type": "text"
      },
      "source": [
        "As well as the decoder model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vURBM_H9LUWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this is OPTIONAL for now\n",
        "# create a placeholder for an encoded (32-dimensional) input, mind it: decoder will take 32 dim as input image(compressed form)\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BXq16fBlL-x",
        "colab_type": "code",
        "outputId": "228acae3-ae60-4b96-a81f-194426636c32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "decoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 784)               25872     \n",
            "=================================================================\n",
            "Total params: 25,872\n",
            "Trainable params: 25,872\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbTnXK2FLXNU",
        "colab_type": "text"
      },
      "source": [
        "Now let's train our autoencoder to reconstruct MNIST digits.\n",
        "\n",
        "First, we'll configure our model to use a per-pixel binary crossentropy loss, and the Adadelta optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upgWrJwbLbwz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "4d0bcd87-eb4b-446d-f491-d0834748f0fc"
      },
      "source": [
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 01:57:59.749517 139742053783424 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0618 01:57:59.775686 139742053783424 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0618 01:57:59.782567 139742053783424 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuVbfOkrLfHp",
        "colab_type": "text"
      },
      "source": [
        "Let's prepare our input data. We're using MNIST digits, and we're discarding the labels (since we're only interested in encoding/decoding the input images)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy-_uI5cLi5x",
        "colab_type": "code",
        "outputId": "d05976c6-f2d6-4d96-e732-35f88258259e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "11501568/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w6op1oYlWgh",
        "colab_type": "code",
        "outputId": "dc188100-3cea-4af1-87ad-861d5068cb74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print type(x_train)\n",
        "print len(x_train)\n",
        "\n",
        "print len(x_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<type 'numpy.ndarray'>\n",
            "60000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFkyfYgslaI7",
        "colab_type": "code",
        "outputId": "0eb54cac-2cb0-4c86-a8e6-29811f648a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "print x_train[0].shape\n",
        "print x_train[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "553ZpGgwLx-k",
        "colab_type": "text"
      },
      "source": [
        "We will normalize all values between 0 and 1 and we will flatten the 28x28 images into vectors of size 784."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RmP54FimVK8",
        "colab_type": "code",
        "outputId": "ebb27a96-94f1-4588-9d10-4a0e498192e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69F8As0ILy3T",
        "colab_type": "code",
        "outputId": "9e2f702d-7a00-491b-8234-3be2ba8e66ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print x_train.shape\n",
        "print x_test.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4EEeUF8L5MD",
        "colab_type": "text"
      },
      "source": [
        "Now let's train our autoencoder for 50 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkzLEKiiL4vE",
        "colab_type": "code",
        "outputId": "1646ce58-15bf-4d45-e372-11ffd9c4f3b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3505
        }
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0618 01:59:28.810817 139742053783424 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 5s 76us/step - loss: 0.3564 - val_loss: 0.2708\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.2633 - val_loss: 0.2523\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.2410 - val_loss: 0.2278\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.2194 - val_loss: 0.2094\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.2043 - val_loss: 0.1970\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1937 - val_loss: 0.1878\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1855 - val_loss: 0.1803\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1786 - val_loss: 0.1740\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1727 - val_loss: 0.1685\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1676 - val_loss: 0.1637\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1630 - val_loss: 0.1594\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1589 - val_loss: 0.1556\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1552 - val_loss: 0.1519\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1518 - val_loss: 0.1486\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1487 - val_loss: 0.1457\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1458 - val_loss: 0.1429\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1432 - val_loss: 0.1402\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1406 - val_loss: 0.1379\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1383 - val_loss: 0.1355\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1360 - val_loss: 0.1332\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1338 - val_loss: 0.1311\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1317 - val_loss: 0.1291\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1297 - val_loss: 0.1271\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1278 - val_loss: 0.1253\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1259 - val_loss: 0.1235\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1242 - val_loss: 0.1217\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1225 - val_loss: 0.1201\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1210 - val_loss: 0.1186\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1195 - val_loss: 0.1172\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1181 - val_loss: 0.1158\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1168 - val_loss: 0.1146\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1156 - val_loss: 0.1135\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1145 - val_loss: 0.1124\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1135 - val_loss: 0.1114\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1125 - val_loss: 0.1105\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1116 - val_loss: 0.1096\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1108 - val_loss: 0.1088\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1100 - val_loss: 0.1081\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1093 - val_loss: 0.1074\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1086 - val_loss: 0.1067\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1080 - val_loss: 0.1061\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1074 - val_loss: 0.1056\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1069 - val_loss: 0.1051\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1064 - val_loss: 0.1046\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1059 - val_loss: 0.1041\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1055 - val_loss: 0.1037\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1051 - val_loss: 0.1033\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1047 - val_loss: 0.1029\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1043 - val_loss: 0.1026\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1040 - val_loss: 0.1022\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1037 - val_loss: 0.1019\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1034 - val_loss: 0.1016\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1031 - val_loss: 0.1014\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1028 - val_loss: 0.1011\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1026 - val_loss: 0.1009\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1023 - val_loss: 0.1006\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1021 - val_loss: 0.1004\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1019 - val_loss: 0.1002\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1017 - val_loss: 0.1000\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1015 - val_loss: 0.0998\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1013 - val_loss: 0.0997\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1012 - val_loss: 0.0995\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1010 - val_loss: 0.0994\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1009 - val_loss: 0.0992\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1007 - val_loss: 0.0991\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1006 - val_loss: 0.0989\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1005 - val_loss: 0.0989\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1004 - val_loss: 0.0987\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1002 - val_loss: 0.0986\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1001 - val_loss: 0.0985\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.1000 - val_loss: 0.0984\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0999 - val_loss: 0.0983\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0999 - val_loss: 0.0983\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0998 - val_loss: 0.0982\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0997 - val_loss: 0.0981\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0996 - val_loss: 0.0980\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0995 - val_loss: 0.0979\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0995 - val_loss: 0.0978\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0994 - val_loss: 0.0978\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0993 - val_loss: 0.0977\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0992 - val_loss: 0.0977\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0992 - val_loss: 0.0976\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0991 - val_loss: 0.0975\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0991 - val_loss: 0.0975\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0990 - val_loss: 0.0974\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0990 - val_loss: 0.0974\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0989 - val_loss: 0.0973\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0988 - val_loss: 0.0973\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0988 - val_loss: 0.0972\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0987 - val_loss: 0.0972\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0987 - val_loss: 0.0971\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0987 - val_loss: 0.0971\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0986 - val_loss: 0.0970\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0986 - val_loss: 0.0970\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0985 - val_loss: 0.0970\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0985 - val_loss: 0.0969\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0984 - val_loss: 0.0969\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0984 - val_loss: 0.0968\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0984 - val_loss: 0.0968\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 1s 16us/step - loss: 0.0983 - val_loss: 0.0968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f181d381290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcfCVk8QMBZ4",
        "colab_type": "text"
      },
      "source": [
        "After 50 epochs, the autoencoder seems to reach a stable train/test loss value of about 0.11. We can try to visualize the reconstructed inputs and the encoded representations. We will use Matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V2Jka62MC0e",
        "colab_type": "code",
        "outputId": "e6305044-75fb-40fb-c07e-315fbc57edbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "#encoded_imgs = encoder.predict(x_test)\n",
        "#decoded_imgs = decoder.predict(encoded_imgs)\n",
        "\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABHwAAAD2CAYAAACk7JCCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6d9d9087d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}