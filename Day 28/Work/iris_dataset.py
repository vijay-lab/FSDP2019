# -*- coding: utf-8 -*-
"""iris dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GAcT95uX1CsHerdgE2rBKmwgC7T2Z4hA

# Classification using Iris Dataset
"""

# Importing libraries
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils
import numpy
import pandas as pd

training_dataset = pd.read_csv('iris_training.csv')
features_train = training_dataset.iloc[:, 0:4].values
labels_train = training_dataset.iloc[:, 4].values

training_dataset.head()

features_train[:5,:]

# Import testing dataset
test_dataset = pd.read_csv('iris_test.csv')
features_test = test_dataset.iloc[:, 0:4].values
labels_test = test_dataset.iloc[:, 4].values

test_dataset.sample()

# Encoding training dataset
encoding_labels_train = np_utils.to_categorical(labels_train)

# Encoding training dataset
encoding_labels_test = np_utils.to_categorical(labels_test)

encoding_labels_train[0]

# Creating a model
model = Sequential()
model.add(Dense(10, input_dim=4, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(3, activation='softmax'))

# Compiling model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Training a model
model.fit(features_train, encoding_labels_train, epochs=100, batch_size=10)

# Evaluate the model
scores = model.evaluate(features_test, encoding_labels_test)
print("\nAccuracy: %.2f%%" % (scores[1]*100))

model.summary()

model.count_params()